{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "### GLOBAL CONSTANTS\n",
    "PATH_STEP1 = '/home/jaum/PG/pg/Final_Output/step1/eemd/'\n",
    "\n",
    "CONFIG_TAG = 'config'\n",
    "SCORE_TAG = 'score'\n",
    "CLF_TAG = 'classifier'\n",
    "\n",
    "KNN_TAG = 'KNeighborsClassifier(n_neighbors=1)'\n",
    "RF_TAG = 'RandomForestClassifier(random_state=1010)'\n",
    "SVM_TAG = 'SVC(random_state=1010)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### METHODS NEEDED\n",
    "\n",
    "#tag = classifier\n",
    "#key_attr = config\n",
    "#ret_attr = score\n",
    "def parse_unique_tag(file_in,tag,key_attr,ret_attr):\n",
    "    \n",
    "    unique_tags = []\n",
    "    for elem in file_in.iter(tag):\n",
    "        if elem.attrib[key_attr[0]] == key_attr[1]:\n",
    "            unique_tags.append(float(elem.attrib[ret_attr]))\n",
    "    return unique_tags\n",
    "\n",
    "def get_clfs_scores(file_in):\n",
    "    knn_score = parse_unique_tag(file_in, CLF_TAG, (CONFIG_TAG, KNN_TAG), SCORE_TAG)\n",
    "    rf_score = parse_unique_tag(file_in, CLF_TAG, (CONFIG_TAG, RF_TAG), SCORE_TAG)\n",
    "    svm_score = parse_unique_tag(file_in, CLF_TAG, (CONFIG_TAG, SVM_TAG), SCORE_TAG)\n",
    "    \n",
    "    return knn_score, rf_score, svm_score\n",
    "\n",
    "def get_score_results_df(normal_file_path, unbiased_file_path, noise):\n",
    "    normal_file = ET.parse(normal_file_path)\n",
    "    unbiased_file = ET.parse(unbiased_file_path)\n",
    "\n",
    "    knn_normal_score, rf_normal_score, svm_normal_score = get_clfs_scores(normal_file)\n",
    "    knn_unbiased_score, rf_unbiased_score, svm_unbiased_score = get_clfs_scores(unbiased_file)\n",
    "\n",
    "    knn_normal_score_by_imfs, rf_normal_score_by_imfs, svm_normal_score_by_imfs = [], [], []\n",
    "    knn_unbiased_score_by_imfs, rf_unbiased_score_by_imfs, svm_unbiased_score_by_imfs = [], [], []\n",
    "    for i,hi_limit in enumerate(range(100,len(knn_normal_score)+1, 100)):\n",
    "        knn_normal_score_by_imfs.append(np.mean(knn_normal_score[i*100:hi_limit]))\n",
    "        rf_normal_score_by_imfs.append(np.mean(rf_normal_score[i*100:hi_limit]))\n",
    "        svm_normal_score_by_imfs.append(np.mean(svm_normal_score[i*100:hi_limit]))\n",
    "\n",
    "        knn_unbiased_score_by_imfs.append(np.mean(knn_unbiased_score[i*100:hi_limit]))\n",
    "        rf_unbiased_score_by_imfs.append(np.mean(rf_unbiased_score[i*100:hi_limit]))\n",
    "        svm_unbiased_score_by_imfs.append(np.mean(svm_unbiased_score[i*100:hi_limit]))\n",
    "\n",
    "    #SEETING UP THE DATAFRAME\n",
    "    normal_idx = ['Normal_Acc_Noise_{0}_Imfs_4'.format(noise),\n",
    "                  'Normal_Acc_Noise_{0}_Imfs_8'.format(noise),\n",
    "                  'Normal_Acc_Noise_{0}_Imfs_16'.format(noise)]\n",
    "    unbiased_idx = ['Unbiased_Acc_Noise_{0}_Imfs_4'.format(noise),\n",
    "                    'Unbiased_Acc_Noise_{0}_Imfs_8'.format(noise),\n",
    "                    'Unbiased_Acc_Noise_{0}_Imfs_16'.format(noise)]\n",
    "    #ss = series\n",
    "    knn_normal_score_ss, rf_normal_score_ss, svm_normal_score_ss  = pd.Series(knn_normal_score_by_imfs, index=normal_idx), \\\n",
    "                                                                    pd.Series(rf_normal_score_by_imfs, index=normal_idx), \\\n",
    "                                                                    pd.Series(svm_normal_score_by_imfs, index=normal_idx)\n",
    "    normal_score_df = pd.DataFrame([knn_normal_score_ss, rf_normal_score_ss, svm_normal_score_ss],\n",
    "                                  index=[KNN_TAG, RF_TAG, SVM_TAG])\n",
    "\n",
    "    knn_unbiased_score_ss, rf_unbiased_score_ss, svm_unbiased_score_ss = pd.Series(knn_unbiased_score_by_imfs,\n",
    "                                                                                   index=unbiased_idx), \\\n",
    "                                                                         pd.Series(rf_unbiased_score_by_imfs,\n",
    "                                                                                   index=unbiased_idx), \\\n",
    "                                                                         pd.Series(svm_unbiased_score_by_imfs, \n",
    "                                                                                   index=unbiased_idx)\n",
    "    unbiased_score_df = pd.DataFrame([knn_unbiased_score_ss, rf_unbiased_score_ss, svm_unbiased_score_ss],\n",
    "                                    index=[KNN_TAG, RF_TAG, SVM_TAG])\n",
    "    \n",
    "    return normal_score_df, unbiased_score_df\n",
    "\n",
    "def get_best_config_df(normal_score_df, unbiased_score_df):\n",
    "    best_normal_knn = np.argmax(normal_score_df.loc[KNN_TAG]), round(max(normal_score_df.loc[KNN_TAG]),6)\n",
    "    best_normal_rf = np.argmax(normal_score_df.loc[RF_TAG]), round(max(normal_score_df.loc[RF_TAG]),6)\n",
    "    best_normal_svm = np.argmax(normal_score_df.loc[SVM_TAG]), round(max(normal_score_df.loc[SVM_TAG]),6)\n",
    "    \n",
    "    best_normal_df = pd.DataFrame([pd.Series({'Best_Normal': best_normal_knn[0], 'Score': best_normal_knn[1]}),\n",
    "                                   pd.Series({'Best_Normal': best_normal_rf[0], 'Score': best_normal_rf[1]}),\n",
    "                                   pd.Series({'Best_Normal': best_normal_svm[0], 'Score': best_normal_svm[1]})],\n",
    "                                  index=[KNN_TAG,RF_TAG,SVM_TAG])\n",
    "\n",
    "    best_unbiased_knn = np.argmax(unbiased_score_df.loc[KNN_TAG]), round(max(unbiased_score_df.loc[KNN_TAG]),6)\n",
    "    best_unbiased_rf = np.argmax(unbiased_score_df.loc[RF_TAG]), round(max(unbiased_score_df.loc[RF_TAG]),6)\n",
    "    best_unbiased_svm = np.argmax(unbiased_score_df.loc[SVM_TAG]), round(max(unbiased_score_df.loc[SVM_TAG]),6)\n",
    "    \n",
    "    best_unbiased_df = pd.DataFrame([pd.Series({'Best_Unbiased': best_unbiased_knn[0], 'Score': best_unbiased_knn[1]}),\n",
    "                                     pd.Series({'Best_Unbiased': best_unbiased_rf[0], 'Score': best_unbiased_rf[1]}),\n",
    "                                     pd.Series({'Best_Unbiased': best_unbiased_svm[0], 'Score': best_unbiased_svm[1]})],\n",
    "                                    index=[KNN_TAG,RF_TAG,SVM_TAG])\n",
    "\n",
    "    return pd.merge(best_normal_df, best_unbiased_df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "def get_all_df(noise_folder,normal_file_name, unbiased_file_name,noise_strength):\n",
    "    normal_file_path = PATH_STEP1 + noise_folder + normal_file_name\n",
    "    unbiased_file_path = PATH_STEP1 + noise_folder + unbiased_file_name\n",
    "    \n",
    "    normal_score_df, unbiased_score_df = get_score_results_df(normal_file_path, unbiased_file_path, noise_strength)\n",
    "    best_config_df = get_best_config_df(normal_score_df, unbiased_score_df)\n",
    "    \n",
    "    return normal_score_df, unbiased_score_df, best_config_df\n",
    "\n",
    "# best_01_df, best_02_df, best_03_df, best_04_df\n",
    "def get_final_df(best_dfs):\n",
    "    knn_best_normal_configs, rf_best_normal_configs, svm_best_normal_configs = [], [], []\n",
    "    knn_best_unbiased_configs, rf_best_unbiased_configs, svm_best_unbiased_configs = [], [], []\n",
    "    #max(lis,key=lambda item:item[1])\n",
    "    for _,best_df in enumerate(best_dfs):\n",
    "        knn_best_normal_configs.append((best_df.loc[KNN_TAG]['Best_Normal'], best_df.loc[KNN_TAG]['Score_x']))\n",
    "        rf_best_normal_configs.append((best_df.loc[RF_TAG]['Best_Normal'], best_df.loc[RF_TAG]['Score_x']))\n",
    "        svm_best_normal_configs.append((best_df.loc[SVM_TAG]['Best_Normal'], best_df.loc[SVM_TAG]['Score_x']))\n",
    "        \n",
    "        knn_best_unbiased_configs.append((best_df.loc[KNN_TAG]['Best_Unbiased'], best_df.loc[KNN_TAG]['Score_y']))\n",
    "        rf_best_unbiased_configs.append((best_df.loc[RF_TAG]['Best_Unbiased'], best_df.loc[RF_TAG]['Score_y']))\n",
    "        svm_best_unbiased_configs.append((best_df.loc[SVM_TAG]['Best_Unbiased'], best_df.loc[SVM_TAG]['Score_y']))\n",
    "    \n",
    "    knn_best_normal = max(knn_best_normal_configs,key=lambda item:item[1])\n",
    "    rf_best_normal = max(rf_best_normal_configs, key=lambda item:item[1])\n",
    "    svm_best_normal = max(svm_best_normal_configs, key=lambda item:item[1])\n",
    "    \n",
    "    best_normal_config_df = pd.DataFrame([pd.Series({'Best_Normal': knn_best_normal[0], 'Score': knn_best_normal[1]}),\n",
    "                                          pd.Series({'Best_Normal': rf_best_normal[0], 'Score': rf_best_normal[1]}),\n",
    "                                          pd.Series({'Best_Normal': svm_best_normal[0], 'Score': svm_best_normal[1]})],\n",
    "                                         index=[KNN_TAG, RF_TAG, SVM_TAG])\n",
    "    \n",
    "    knn_best_unbiased = max(knn_best_unbiased_configs, key=lambda item:item[1])\n",
    "    rf_best_unbiased = max(rf_best_unbiased_configs, key=lambda item:item[1])\n",
    "    svm_best_unbiased = max(svm_best_unbiased_configs, key=lambda item:item[1])\n",
    "    \n",
    "    best_unbiased_config_df = pd.DataFrame([pd.Series({'Best_Unbiased': knn_best_unbiased[0], 'Score': knn_best_unbiased[1]}),\n",
    "                                          pd.Series({'Best_Unbiased': rf_best_unbiased[0], 'Score': rf_best_unbiased[1]}),\n",
    "                                          pd.Series({'Best_Unbiased': svm_best_unbiased[0], 'Score': svm_best_unbiased[1]})],\n",
    "                                         index=[KNN_TAG, RF_TAG, SVM_TAG])\n",
    "    \n",
    "    return pd.merge(best_normal_config_df, best_unbiased_config_df, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOISE = 0.01 --> Analyzing the best EEMD number of IMFs for both NORMAL and UNBIASED experiments with ACCURACY score\n",
    "NOISE_001_FOLDER = 'noise_001/'\n",
    "NORMAL_ACC_RESULTS_FILE = 'step1_eemd001_normal_acc_results.xml'\n",
    "UNBIASED_ACC_RESULTS_FILE = 'step1_eemd001_unbiased_acc_results.xml'\n",
    "\n",
    "normal_001_score_df, unbiased_001_score_df, best_001_config_df = get_all_df(NOISE_001_FOLDER, NORMAL_ACC_RESULTS_FILE,\n",
    "                                                                            UNBIASED_ACC_RESULTS_FILE, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_001_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unbiased_001_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_001_config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOISE = 0.05 --> Analyzing the best EEMD number of IMFs for both NORMAL and UNBIASED experiments with ACCURACY score\n",
    "NOISE_005_FOLDER = 'noise_005/'\n",
    "NORMAL_ACC_RESULTS_FILE = 'step1_eemd005_normal_acc_results.xml'\n",
    "UNBIASED_ACC_RESULTS_FILE = 'step1_eemd005_unbiased_acc_results.xml'\n",
    "\n",
    "normal_005_score_df, unbiased_005_score_df, best_005_config_df = get_all_df(NOISE_005_FOLDER, NORMAL_ACC_RESULTS_FILE,\n",
    "                                                                            UNBIASED_ACC_RESULTS_FILE, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_005_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unbiased_005_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_005_config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOISE = 0.01 --> Analyzing the best EEMD number of IMFs for both NORMAL and UNBIASED experiments with ACCURACY score\n",
    "NOISE_01_FOLDER = 'noise_01/'\n",
    "NORMAL_ACC_RESULTS_FILE = 'step1_eemd01_normal_acc_results.xml'\n",
    "UNBIASED_ACC_RESULTS_FILE = 'step1_eemd01_unbiased_acc_results.xml'\n",
    "\n",
    "normal_01_score_df, unbiased_01_score_df, best_01_config_df = get_all_df(NOISE_01_FOLDER, NORMAL_ACC_RESULTS_FILE,\n",
    "                                                                            UNBIASED_ACC_RESULTS_FILE, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_01_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unbiased_01_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_01_config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOISE = 0.2 --> Analyzing the best EEMD number of IMFs for both NORMAL and UNBIASED experiments with ACCURACY score\n",
    "NOISE_02_FOLDER = 'noise_02/'\n",
    "NORMAL_ACC_RESULTS_FILE = 'step1_eemd02_normal_acc_results.xml'\n",
    "UNBIASED_ACC_RESULTS_FILE = 'step1_eemd02_unbiased_acc_results.xml'\n",
    "\n",
    "normal_02_score_df, unbiased_02_score_df, best_02_config_df = get_all_df(NOISE_02_FOLDER, NORMAL_ACC_RESULTS_FILE,\n",
    "                                                                            UNBIASED_ACC_RESULTS_FILE, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_02_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unbiased_02_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_02_config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOISE = 0.3 --> Analyzing the best EEMD number of IMFs for both NORMAL and UNBIASED experiments with ACCURACY score\n",
    "NOISE_03_FOLDER = 'noise_03/'\n",
    "NORMAL_ACC_RESULTS_FILE = 'step1_eemd03_normal_acc_results.xml'\n",
    "UNBIASED_ACC_RESULTS_FILE = 'step1_eemd03_unbiased_acc_results.xml'\n",
    "\n",
    "normal_03_score_df, unbiased_03_score_df, best_03_config_df = get_all_df(NOISE_03_FOLDER, NORMAL_ACC_RESULTS_FILE,\n",
    "                                                                            UNBIASED_ACC_RESULTS_FILE, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_03_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unbiased_03_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_03_config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOISE = 0.4 --> Analyzing the best EEMD number of IMFs for both NORMAL and UNBIASED experiments with ACCURACY score\n",
    "NOISE_04_FOLDER = 'noise_04/'\n",
    "NORMAL_ACC_RESULTS_FILE = 'step1_eemd04_normal_acc_results.xml'\n",
    "UNBIASED_ACC_RESULTS_FILE = 'step1_eemd04_unbiased_acc_results.xml'\n",
    "\n",
    "normal_04_score_df, unbiased_04_score_df, best_04_config_df = get_all_df(NOISE_04_FOLDER, NORMAL_ACC_RESULTS_FILE,\n",
    "                                                                            UNBIASED_ACC_RESULTS_FILE, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_04_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unbiased_04_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_04_config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_configs = [best_001_config_df, best_005_config_df, best_01_config_df,\n",
    "                best_02_config_df, best_03_config_df,best_04_config_df]\n",
    "get_final_df(best_configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
